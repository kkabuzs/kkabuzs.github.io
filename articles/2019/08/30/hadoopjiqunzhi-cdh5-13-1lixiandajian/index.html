<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Hadoop集群之 CDH v5.13.1 搭建 (离线本地Parcels） | kkabuzs博客屋</title><meta name="author" content="Kkabuzs"><meta name="copyright" content="Kkabuzs"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="无论你跑多少距离，放弃很容易，停下来，肉体得到暂时的舒服，但你最终会一无所得。坚持或许很难，但你最后一定会有所收获，跑过的路，永远不会欺骗自己。  Hadoop集群之 CDH v5.13.1 搭建 (离线本地Parcels）一，CDH Parcels 离线安装 官方一共给了三种方法：  Installation Path A - Automated Installation by Clouder">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop集群之 CDH v5.13.1 搭建 (离线本地Parcels）">
<meta property="og:url" content="https://kkabuzs.github.io/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/index.html">
<meta property="og:site_name" content="kkabuzs博客屋">
<meta property="og:description" content="无论你跑多少距离，放弃很容易，停下来，肉体得到暂时的舒服，但你最终会一无所得。坚持或许很难，但你最后一定会有所收获，跑过的路，永远不会欺骗自己。  Hadoop集群之 CDH v5.13.1 搭建 (离线本地Parcels）一，CDH Parcels 离线安装 官方一共给了三种方法：  Installation Path A - Automated Installation by Clouder">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://kkabuzs.github.io/themes-img/touxiang.jpg">
<meta property="article:published_time" content="2019-08-30T02:09:25.000Z">
<meta property="article:modified_time" content="2019-08-30T02:09:25.000Z">
<meta property="article:author" content="Kkabuzs">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kkabuzs.github.io/themes-img/touxiang.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Hadoop集群之 CDH v5.13.1 搭建 (离线本地Parcels）",
  "url": "https://kkabuzs.github.io/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/",
  "image": "https://kkabuzs.github.io/themes-img/touxiang.jpg",
  "datePublished": "2019-08-30T02:09:25.000Z",
  "dateModified": "2019-08-30T02:09:25.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "Kkabuzs",
      "url": "https://kkabuzs.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/themes-img/touxiang.jpg"><link rel="canonical" href="https://kkabuzs.github.io/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hadoop集群之 CDH v5.13.1 搭建 (离线本地Parcels）',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/themes-img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">77</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/themes-img/yinhe.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/themes-img/touxiang.jpg" alt="Logo"><span class="site-name">kkabuzs博客屋</span></a><a class="nav-page-title" href="/"><span class="site-name">Hadoop集群之 CDH v5.13.1 搭建 (离线本地Parcels）</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Hadoop集群之 CDH v5.13.1 搭建 (离线本地Parcels）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-08-30T02:09:25.000Z" title="发表于 2019-08-30 10:09:25">2019-08-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2019-08-30T02:09:25.000Z" title="更新于 2019-08-30 10:09:25">2019-08-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><blockquote>
<p><em>无论你跑多少距离，放弃很容易，停下来，肉体得到暂时的舒服，但你最终会一无所得。</em><br><em>坚持或许很难，但你最后一定会有所收获，跑过的路，永远不会欺骗自己。</em></p>
</blockquote>
<h1 id="Hadoop集群之-CDH-v5-13-1-搭建-离线本地Parcels）"><a href="#Hadoop集群之-CDH-v5-13-1-搭建-离线本地Parcels）" class="headerlink" title="Hadoop集群之 CDH v5.13.1 搭建 (离线本地Parcels）"></a>Hadoop集群之 CDH v5.13.1 搭建 (离线本地Parcels）</h1><h2 id="一，CDH-Parcels-离线安装"><a href="#一，CDH-Parcels-离线安装" class="headerlink" title="一，CDH Parcels 离线安装"></a>一，CDH Parcels 离线安装</h2><blockquote>
<p><strong>官方一共给了三种方法：</strong></p>
<ul>
<li><strong>Installation Path A - Automated Installation by Cloudera Manager</strong>：要求所有机器都能连网，而且外国网站不太稳定。一旦失败，重装非常痛苦。</li>
<li><strong>Installation Path B - Manual Installation Using Cloudera Manager Packages</strong>：设置Red Hat&#x2F;CentOS或者Debian&#x2F;Ubuntu，下载系统package安装，下载量数目众多</li>
<li><strong>Installation Path C - Manual Installation Using Tarballs and Parcels安装步骤</strong>：该方法对系统侵入性最小,最大优点可实现全离线安装，而且重装什么的都非常方便。后期的集群统一包升级也非常好</li>
</ul>
</blockquote>
<p><strong>在这里，优雅的我们必须使用优雅的方法，显然是第三种</strong></p>
<h3 id="1-1-本地源与Package本地源的区别"><a href="#1-1-本地源与Package本地源的区别" class="headerlink" title="1.1 本地源与Package本地源的区别"></a>1.1 本地源与Package本地源的区别</h3><blockquote>
<p><strong>本地通过Parcel安装过程与本地通过Package安装过程完全一致，不同的是两者的本地源的配置。<br>区别如下：</strong></p>
<ul>
<li>Package本地源：软件包是.rpm格式的，数量通常较多，下载的时候比较麻烦。通过<code>createrepo .</code>的命令创建源，并要放到存放源文件主机的web服务器的根目录下。</li>
<li>Parcel本地源：软件包是以.parcel结尾，相当于压缩包格式的，一个系统版本对应一个，下载的时候方便。</li>
</ul>
</blockquote>
<h2 id="二，使用-Parcels-离线部署-CDH"><a href="#二，使用-Parcels-离线部署-CDH" class="headerlink" title="二，使用 Parcels 离线部署 CDH"></a>二，使用 Parcels 离线部署 CDH</h2><h3 id="2-1-环境介绍"><a href="#2-1-环境介绍" class="headerlink" title="2.1 环境介绍"></a>2.1 环境介绍</h3><table>
<thead>
<tr>
<th>主机名</th>
<th>ip</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>hadoop1</td>
<td>192.168.101.116</td>
<td>主</td>
</tr>
<tr>
<td>hadoop2</td>
<td>192.168.101.49</td>
<td>从</td>
</tr>
<tr>
<td>hadoop3</td>
<td>192.168.101.229</td>
<td>从</td>
</tr>
</tbody></table>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#所有节点关闭防火墙和selinux</span></span><br><span class="line">[root@hadoop1 ~]# systemctl stop firewalld</span><br><span class="line">[root@hadoop1 ~]# systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line">Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.</span><br><span class="line">Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@hadoop1 ~]# vim /etc/selinux/config</span><br><span class="line">将</span><br><span class="line">SELINUX=enforcing</span><br><span class="line">改为</span><br><span class="line">SELINUX=disabled</span><br><span class="line"></span><br><span class="line">[root@hadoop1 ~]# setenforce 0</span><br><span class="line"></span><br><span class="line"><span class="comment">#配置hosts映射</span></span><br><span class="line">[root@hadoop1 ~]# vim /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">192.168.101.116 hadoop1</span><br><span class="line">192.168.101.49 hadoop2</span><br><span class="line">192.168.101.229 hadoop3</span><br><span class="line"></span><br><span class="line"><span class="comment">#scp到两台从</span></span><br><span class="line">[root@hadoop1 ~]# scp /etc/hosts hadoop2:/etc/</span><br><span class="line">root@hadoop2<span class="string">&#x27;s password:</span></span><br><span class="line"><span class="string">hosts                                        100%  231   658.0KB/s   00:00</span></span><br><span class="line"><span class="string">[root@hadoop1 ~]# scp /etc/hosts hadoop3:/etc/</span></span><br><span class="line"><span class="string">root@hadoop3&#x27;</span>s password:</span><br><span class="line">hosts                                        100%  231   440.1KB/s   00:00</span><br><span class="line"></span><br><span class="line"><span class="comment">#安装jdk（所有机器）</span></span><br><span class="line">[root@hadoop1 ~]# wget https://github.com/frekele/oracle-java/releases/download/8u181-b13/jdk-8u181-linux-x64.tar.gz</span><br><span class="line">[root@hadoop1 ~]# tar xf jdk-8u181-linux-x64.tar.gz -C /usr/local/</span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">ln</span> -s /usr/local/jdk1.8.0_181 /usr/local/jdk</span><br><span class="line"><span class="comment">#配置java环境变量</span></span><br><span class="line">[root@hadoop1 ~]# sed -i.ori <span class="string">&#x27;$a export JAVA_HOME=/usr/local/jdk\nexport PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH\nexport CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar&#x27;</span> /etc/profile</span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">tail</span> -3 /etc/profile</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/local/jdk</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$JAVA_HOME</span>/jre/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.<span class="variable">$CLASSPATH</span>:<span class="variable">$JAVA_HOME</span>/lib:<span class="variable">$JAVA_HOME</span>/lib/tools.jar</span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">source</span> /etc/profile</span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">which</span> java</span><br><span class="line">/usr/local/jdk/bin/java</span><br><span class="line">[root@hadoop1 ~]# java -version</span><br><span class="line">java version <span class="string">&quot;1.8.0_181&quot;</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_181-b13)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode)</span><br></pre></td></tr></table></figure>

<h3 id="2-2-部署Cloudera-Manager"><a href="#2-2-部署Cloudera-Manager" class="headerlink" title="2.2 部署Cloudera Manager"></a>2.2 部署Cloudera Manager</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载二进制安装包</span></span><br><span class="line">[root@hadoop1 ~]# wget https://archive.cloudera.com/cm5/cm/5/cloudera-manager-centos7-cm5.13.3_x86_64.tar.gz</span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">ls</span></span><br><span class="line">anaconda-ks.cfg  cloudera-manager-centos7-cm5.13.3_x86_64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">#先把安装包copy到其他两台机器</span></span><br><span class="line">[root@hadoop1 ~]# scp cloudera-manager-centos7-cm5.13.3_x86_64.tar.gz hadoop2:~</span><br><span class="line">[root@hadoop1 ~]# scp cloudera-manager-centos7-cm5.13.3_x86_64.tar.gz hadoop3:~</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建解压目录(三台都创建)</span></span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">mkdir</span> /usr/local/cloudera-manager</span><br><span class="line"></span><br><span class="line"><span class="comment">#解压cloudera-manager-centos7-cm5.13.3_x86_64.tar.gz（三台机器）</span></span><br><span class="line">[root@hadoop1 ~]# tar xf cloudera-manager-centos7-cm5.13.3_x86_64.tar.gz -C /usr/local/cloudera-manager</span><br></pre></td></tr></table></figure>

<h4 id="2-2-1-在所有的节点上创建clodera-scm用户"><a href="#2-2-1-在所有的节点上创建clodera-scm用户" class="headerlink" title="2.2.1 在所有的节点上创建clodera-scm用户"></a>2.2.1 在所有的节点上创建clodera-scm用户</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 ~]# useradd --system --no-create-home --shell=/bin/false --comment <span class="string">&quot;Cloudera SCM User&quot;</span> cloudera-scm</span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">id</span> cloudera-scm</span><br><span class="line">uid=998(cloudera-scm) gid=996(cloudera-scm) 组=996(cloudera-scm)</span><br><span class="line"></span><br><span class="line"><span class="comment">#参数解读：</span></span><br><span class="line">-r, --system                  创建一个系统账户</span><br><span class="line">-M, --no-create-home		  不创建用户的主目录</span><br><span class="line">-s, --shell SHELL	       	  新账户的登录 shell</span><br><span class="line">-c, --comment COMMENT         新账户的 GECOS 字段</span><br></pre></td></tr></table></figure>

<h4 id="2-2-2-修改Cloudera-Manager-Agent端的配置文件-所有机器"><a href="#2-2-2-修改Cloudera-Manager-Agent端的配置文件-所有机器" class="headerlink" title="2.2.2 修改Cloudera Manager Agent端的配置文件(所有机器)"></a>2.2.2 修改Cloudera Manager Agent端的配置文件(所有机器)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 ~]# vim /usr/local/cloudera-manager/cm-5.13.3/etc/cloudera-scm-agent/config.ini</span><br><span class="line">server_host=localhost</span><br><span class="line">改为：</span><br><span class="line">server_host=hadoop1</span><br></pre></td></tr></table></figure>

<h4 id="2-2-3-初始化CM-Server数据库"><a href="#2-2-3-初始化CM-Server数据库" class="headerlink" title="2.2.3 初始化CM Server数据库"></a>2.2.3 初始化CM Server数据库</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先要有一个mysql数据库</span></span><br><span class="line">[root@hadoop1 ~]# rpm -qa | grep mysql      <span class="comment">#没有安装</span></span><br><span class="line">[root@hadoop1 ~]#</span><br><span class="line"></span><br><span class="line">[root@hadoop1 ~]# rpm -Uvh http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看mysql可用安装</span></span><br><span class="line">[root@hadoop1 ~]# yum repolist enabled | grep <span class="string">&quot;mysql.*-community.*&quot;</span></span><br><span class="line">mysql-connectors-community/x86_64       MySQL Connectors Community           118</span><br><span class="line">mysql-tools-community/x86_64            MySQL Tools Community                 95</span><br><span class="line">mysql56-community/x86_64                MySQL 5.6 Community Server           479</span><br><span class="line"></span><br><span class="line"><span class="comment">#安装mysql 5.6</span></span><br><span class="line">[root@hadoop1 ~]# yum -y install mysql-community-server</span><br><span class="line"></span><br><span class="line"><span class="comment">#加入开机启动，启动服务</span></span><br><span class="line">systemctl <span class="built_in">enable</span> mysqld</span><br><span class="line">systemctl start mysqld</span><br><span class="line"></span><br><span class="line"><span class="comment">#配置mysql（设置root密码等）：</span></span><br><span class="line">[root@zhaohadoop3 ~]# mysql_secure_installation</span><br><span class="line"></span><br><span class="line">NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MySQL</span><br><span class="line">      SERVERS IN PRODUCTION USE!  PLEASE READ EACH STEP CAREFULLY!</span><br><span class="line"></span><br><span class="line">In order to <span class="built_in">log</span> into MySQL to secure it, we<span class="string">&#x27;ll need the current</span></span><br><span class="line"><span class="string">password for the root user.  If you&#x27;</span>ve just installed MySQL, and</span><br><span class="line">you haven<span class="string">&#x27;t set the root password yet, the password will be blank,</span></span><br><span class="line"><span class="string">so you should just press enter here.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Enter current password for root (enter for none):       #回车</span></span><br><span class="line"><span class="string">OK, successfully used password, moving on...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Setting the root password ensures that nobody can log into the MySQL</span></span><br><span class="line"><span class="string">root user without the proper authorisation.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Set root password? [Y/n] y          [设置root用户密码]</span></span><br><span class="line"><span class="string">New password:       123456</span></span><br><span class="line"><span class="string">Re-enter new password:      123456</span></span><br><span class="line"><span class="string">Password updated successfully!</span></span><br><span class="line"><span class="string">Reloading privilege tables..</span></span><br><span class="line"><span class="string"> ... Success!</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">By default, a MySQL installation has an anonymous user, allowing anyone</span></span><br><span class="line"><span class="string">to log into MySQL without having to have a user account created for</span></span><br><span class="line"><span class="string">them.  This is intended only for testing, and to make the installation</span></span><br><span class="line"><span class="string">go a bit smoother.  You should remove them before moving into a</span></span><br><span class="line"><span class="string">production environment.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Remove anonymous users? [Y/n] y     [删除匿名用户]</span></span><br><span class="line"><span class="string"> ... Success!</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Normally, root should only be allowed to connect from &#x27;</span>localhost<span class="string">&#x27;.  This</span></span><br><span class="line"><span class="string">ensures that someone cannot guess at the root password from the network.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Disallow root login remotely? [Y/n] n       [禁止root远程登录]</span></span><br><span class="line"><span class="string"> ... skipping.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">By default, MySQL comes with a database named &#x27;</span><span class="built_in">test</span><span class="string">&#x27; that anyone can</span></span><br><span class="line"><span class="string">access.  This is also intended only for testing, and should be removed</span></span><br><span class="line"><span class="string">before moving into a production environment.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Remove test database and access to it? [Y/n] y      [删除test数据库]</span></span><br><span class="line"><span class="string"> - Dropping test database...</span></span><br><span class="line"><span class="string">ERROR 1008 (HY000) at line 1: Can&#x27;</span>t drop database <span class="string">&#x27;test&#x27;</span>; database doesn<span class="string">&#x27;t exist</span></span><br><span class="line"><span class="string"> ... Failed!  Not critical, keep moving...</span></span><br><span class="line"><span class="string"> - Removing privileges on test database...</span></span><br><span class="line"><span class="string"> ... Success!</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Reloading the privilege tables will ensure that all changes made so far</span></span><br><span class="line"><span class="string">will take effect immediately.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Reload privilege tables now? [Y/n] y        [刷新权限]</span></span><br><span class="line"><span class="string"> ... Success!</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">All done!  If you&#x27;</span>ve completed all of the above steps, your MySQL</span><br><span class="line">installation should now be secure.</span><br><span class="line"></span><br><span class="line">Thanks <span class="keyword">for</span> using MySQL!</span><br><span class="line"></span><br><span class="line">Cleaning up...</span><br><span class="line"></span><br><span class="line"><span class="comment">#登陆数据库，创建初始化CM Server用户</span></span><br><span class="line">mysql&gt; GRANT ALL PRIVILEGES ON *.* TO <span class="string">&#x27;cdh&#x27;</span>@<span class="string">&#x27;192.168.101.%&#x27;</span> IDENTIFIED BY <span class="string">&#x27;111111&#x27;</span> WITH GRANT OPTION;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">[root@hadoop1 schema]# yum -y install mysql-connector-java</span><br><span class="line"></span><br><span class="line"><span class="comment">#######第二种方法：把jar包拷贝到/usr/share/java下</span></span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">mkdir</span> /usr/share/java</span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">mv</span> mysql-connector-java.jar /usr/share/java</span><br><span class="line"></span><br><span class="line"><span class="comment">#######</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化CM Server数据库</span></span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">cd</span> /usr/local/cloudera-manager/cm-5.13.3/share/cmf/schema/</span><br><span class="line">[root@hadoop1 schema]# ./scm_prepare_database.sh mysql cdh -h hadoop1 -ucdh -p111111 --scm-host hadoop1 scm scm scm       <span class="comment">#其格式为：数据库类型，数据库，数据库服务器，用户名，密码，CM服务器，后面的三个scm请不要改动！</span></span><br><span class="line">JAVA_HOME=/usr/local/jdk</span><br><span class="line">Verifying that we can write to /usr/local/cloudera-manager/cm-5.13.3/etc/cloudera-scm-server</span><br><span class="line">Creating SCM configuration file <span class="keyword">in</span> /usr/local/cloudera-manager/cm-5.13.3/etc/cloudera-scm-server</span><br><span class="line">Executing:  /usr/local/jdk/bin/java -<span class="built_in">cp</span> /usr/share/java/mysql-connector-java.jar:/usr/share/java/oracle-connector-java.jar:/usr/local/cloudera-manager/cm-5.13.3/share/cmf/schema/../lib/* com.cloudera.enterprise.dbutil.DbCommandExecutor /usr/local/cloudera-manager/cm-5.13.3/etc/cloudera-scm-server/db.properties com.cloudera.cmf.db.</span><br><span class="line">2019-09-02 11:23:13,182 [main] INFO  com.cloudera.enterprise.dbutil.DbCommandExecutor  - Successfully connected to database.      <span class="comment">#成功</span></span><br><span class="line">All <span class="keyword">done</span>, your SCM database is configured correctly!</span><br></pre></td></tr></table></figure>

<p><strong>检查数据库内容</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 ~]# mysql -uroot -p</span><br><span class="line">Enter password:</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection <span class="built_in">id</span> is 17</span><br><span class="line">Server version: 5.6.45 MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type <span class="string">&#x27;help;&#x27;</span> or <span class="string">&#x27;\h&#x27;</span> <span class="keyword">for</span> <span class="built_in">help</span>. Type <span class="string">&#x27;\c&#x27;</span> to clear the current input statement.</span><br><span class="line"></span><br><span class="line">mysql&gt; show databases;</span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| cdh                |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">+--------------------+</span><br><span class="line">4 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; use cdh;</span><br><span class="line">Database changed</span><br><span class="line">mysql&gt; show tables;</span><br><span class="line">Empty <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; quit</span><br><span class="line">Bye</span><br></pre></td></tr></table></figure>

<h3 id="2-3-制作CDH本地源"><a href="#2-3-制作CDH本地源" class="headerlink" title="2.3 制作CDH本地源"></a>2.3 制作CDH本地源</h3><h4 id="2-3-1-server创建parcel-repo目录"><a href="#2-3-1-server创建parcel-repo目录" class="headerlink" title="2.3.1 server创建parcel-repo目录"></a>2.3.1 server创建parcel-repo目录</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 ~]# <span class="built_in">mkdir</span> -p /opt/cloudera/parcel-repo        <span class="comment">#Server端创建Parcel-repo目录，用于存放离线CDH文件</span></span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">chown</span> cloudera-scm:cloudera-scm /opt/cloudera/parcel-repo/      <span class="comment">#别忘记把权限给赋给我们之前创建的cloudera-scm用户</span></span><br><span class="line">[root@hadoop1 ~]# ll -d  /opt/cloudera/parcel-repo/</span><br><span class="line">drwxr-xr-x. 2 cloudera-scm cloudera-scm 6 9月   2 11:34 /opt/cloudera/parcel-repo/</span><br></pre></td></tr></table></figure>

<h4 id="2-3-2-agent端创建parcels目录-49和229机器"><a href="#2-3-2-agent端创建parcels目录-49和229机器" class="headerlink" title="2.3.2 agent端创建parcels目录(49和229机器)"></a>2.3.2 agent端创建parcels目录(49和229机器)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop2 ~]# <span class="built_in">mkdir</span> -p /opt/cloudera/parcels</span><br><span class="line">[root@hadoop2 ~]# <span class="built_in">chown</span> cloudera-scm:cloudera-scm /opt/cloudera/parcels</span><br><span class="line">[root@hadoop2 ~]# <span class="built_in">ls</span> -ld /opt/cloudera/parcels</span><br><span class="line">drwxr-xr-x. 2 cloudera-scm cloudera-scm 6 9月   2 13:39 /opt/cloudera/parcels</span><br></pre></td></tr></table></figure>

<h4 id="2-3-3-制作CDH本地源"><a href="#2-3-3-制作CDH本地源" class="headerlink" title="2.3.3 制作CDH本地源"></a>2.3.3 制作CDH本地源</h4><blockquote>
<p>paecel官方下载网址：<a target="_blank" rel="noopener" href="http://archive.cloudera.com/cdh5/parcels/">http://archive.cloudera.com/cdh5/parcels/</a></p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 ~]# wget http://archive.cloudera.com/cdh5/parcels/5.13.3/CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel</span><br><span class="line">[root@hadoop1 ~]# wget http://archive.cloudera.com/cdh5/parcels/5.13.3/CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel.sha1</span><br><span class="line">[root@hadoop1 ~]# wget http://archive.cloudera.com/cdh5/parcels/5.13.3/manifest.json</span><br><span class="line"></span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">mv</span> CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel /opt/cloudera/parcel-repo</span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">mv</span> CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel.sha1 /opt/cloudera/parcel-repo/CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel.sha    <span class="comment">#注意 这里我改名了</span></span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">mv</span> manifest.json /opt/cloudera/parcel-repo/</span><br><span class="line">[root@hadoop1 ~]# ll /opt/cloudera/parcel-repo/</span><br><span class="line">总用量 1889856</span><br><span class="line">-rw-r--r--. 1 root root 1935128068 4月   5 2018 CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel</span><br><span class="line">-rw-r--r--. 1 root root         41 4月   5 2018 CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel.sha</span><br><span class="line">-rw-r--r--. 1 root root      73766 4月   5 2018 manifest.json</span><br><span class="line"></span><br><span class="line">温馨提示：</span><br><span class="line">        如果你没有下载到“CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel.sha”文件是，可以找到“manifest.json”文件中<span class="string">&quot;parcelName&quot;</span>: <span class="string">&quot;CDH-5.13.3-1.cdh5.13.3.p0.2-el7.parcel.sha&quot;</span>对应的<span class="string">&quot;hash&quot;</span>: <span class="string">&quot;1dce02d58ab5c336d861ed2e62f5745e2fca5afe&quot;</span>复制到该文件即可。这个方法也适用于其他的版本！</span><br></pre></td></tr></table></figure>

<h3 id="2-4-启动CM的Server，Agent端"><a href="#2-4-启动CM的Server，Agent端" class="headerlink" title="2.4 启动CM的Server，Agent端"></a>2.4 启动CM的Server，Agent端</h3><h4 id="2-4-1-启动Cloudera-Manager-Server端"><a href="#2-4-1-启动Cloudera-Manager-Server端" class="headerlink" title="2.4.1 启动Cloudera Manager Server端"></a>2.4.1 启动Cloudera Manager Server端</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 ~]# /usr/local/cloudera-manager/cm-5.13.3/etc/init.d/cloudera-scm-server start</span><br><span class="line">Starting cloudera-scm-server:                              [  确定  ]</span><br><span class="line">[root@hadoop1 init.d]# /usr/local/cloudera-manager/cm-5.13.3/etc/init.d/cloudera-scm-server status</span><br><span class="line">cloudera-scm-server (pid  24714) 正在运行...</span><br></pre></td></tr></table></figure>

<p><strong>我们需要观察Server的日志文件，如果出现以下内容说明启动成功</strong></p>
<p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/1.png"></p>
<h4 id="2-4-2-启动Cloudera-Manager-Agent端"><a href="#2-4-2-启动Cloudera-Manager-Agent端" class="headerlink" title="2.4.2 启动Cloudera Manager Agent端"></a>2.4.2 启动Cloudera Manager Agent端</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 ~]# /usr/local/cloudera-manager/cm-5.13.3/etc/init.d/cloudera-scm-agent start</span><br><span class="line">Starting cloudera-scm-agent:                               [  确定  ]</span><br><span class="line">[root@hadoop1 ~]# /usr/local/cloudera-manager/cm-5.13.3/etc/init.d/cloudera-scm-agent status</span><br><span class="line">cloudera-scm-agent (pid  24942) 正在运行...</span><br><span class="line"></span><br><span class="line">[root@hadoop2 ~]# /usr/local/cloudera-manager/cm-5.13.3/etc/init.d/cloudera-scm-agent start</span><br><span class="line">Starting cloudera-scm-agent:                               [  确定  ]</span><br><span class="line">[root@hadoop2 ~]# /usr/local/cloudera-manager/cm-5.13.3/etc/init.d/cloudera-scm-agent status</span><br><span class="line">cloudera-scm-agent (pid  23528) 正在运行...</span><br><span class="line"></span><br><span class="line">[root@hadoop3 ~]# /usr/local/cloudera-manager/cm-5.13.3/etc/init.d/cloudera-scm-agent start</span><br><span class="line">Starting cloudera-scm-agent:                               [  确定  ]</span><br><span class="line">[root@hadoop3 ~]# /usr/local/cloudera-manager/cm-5.13.3/etc/init.d/cloudera-scm-agent status</span><br><span class="line">cloudera-scm-agent (pid  23957) 正在运行...</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-5-访问webUI界面"><a href="#2-5-访问webUI界面" class="headerlink" title="2.5 访问webUI界面"></a>2.5 访问webUI界面</h3><blockquote>
<p>我们安装CM的过程通过WebUI的安装向导来进行安装，推荐使用谷歌浏览器，不要使用容易崩溃的浏览器，这样会影响你安装进度的！如果你也出现了以下界面，恭喜你CM部署成功。</p>
</blockquote>
<p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/2.png"></p>
<h2 id="三，基于CM的WebUI部署CDH集群"><a href="#三，基于CM的WebUI部署CDH集群" class="headerlink" title="三，基于CM的WebUI部署CDH集群"></a>三，基于CM的WebUI部署CDH集群</h2><h3 id="3-1-CM的webUI界面默认的用户名-密码都是小写的admin"><a href="#3-1-CM的webUI界面默认的用户名-密码都是小写的admin" class="headerlink" title="3.1 CM的webUI界面默认的用户名&#x2F;密码都是小写的admin"></a>3.1 CM的webUI界面默认的用户名&#x2F;密码都是小写的admin</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/3.png"></p>
<h3 id="3-2-同意并继续"><a href="#3-2-同意并继续" class="headerlink" title="3.2 同意并继续"></a>3.2 同意并继续</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/4.png"></p>
<h3 id="3-3-选择CM的免费版本"><a href="#3-3-选择CM的免费版本" class="headerlink" title="3.3 选择CM的免费版本"></a>3.3 选择CM的免费版本</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/5.png"></p>
<h3 id="3-4-点击继续"><a href="#3-4-点击继续" class="headerlink" title="3.4 点击继续"></a>3.4 点击继续</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/6.png"></p>
<h3 id="3-5-为-CDH-群集安装指定主机"><a href="#3-5-为-CDH-群集安装指定主机" class="headerlink" title="3.5 为 CDH 群集安装指定主机"></a>3.5 为 CDH 群集安装指定主机</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/7.png"></p>
<h3 id="3-6-选择CDH本地版本（即我们自己下载好的版本）"><a href="#3-6-选择CDH本地版本（即我们自己下载好的版本）" class="headerlink" title="3.6 选择CDH本地版本（即我们自己下载好的版本）"></a>3.6 选择CDH本地版本（即我们自己下载好的版本）</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/8.png"></p>
<p><strong>CDH的默认存放路径介绍</strong></p>
<p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/9.png"></p>
<h3 id="3-7-当CDH安装完毕后，点击继续"><a href="#3-7-当CDH安装完毕后，点击继续" class="headerlink" title="3.7 当CDH安装完毕后，点击继续"></a>3.7 当CDH安装完毕后，点击继续</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/10.png"></p>
<h3 id="3-8-等待检查主机完成"><a href="#3-8-等待检查主机完成" class="headerlink" title="3.8 等待检查主机完成"></a>3.8 等待检查主机完成</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/11.png"></p>
<h3 id="3-9-我们可以根据下面的提示去相应的服务器做具体的操作，做完操作后点击“重新运行”以验证你是否配置成功！"><a href="#3-9-我们可以根据下面的提示去相应的服务器做具体的操作，做完操作后点击“重新运行”以验证你是否配置成功！" class="headerlink" title="3.9 我们可以根据下面的提示去相应的服务器做具体的操作，做完操作后点击“重新运行”以验证你是否配置成功！"></a>3.9 我们可以根据下面的提示去相应的服务器做具体的操作，做完操作后点击“重新运行”以验证你是否配置成功！</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/12.png"></p>
<h3 id="3-10-解决告警信息后，点击完成"><a href="#3-10-解决告警信息后，点击完成" class="headerlink" title="3.10 解决告警信息后，点击完成"></a>3.10 解决告警信息后，点击完成</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#解决Cloudera 建议将 /proc/sys/vm/swappiness 设置为最大值 10问题</span></span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">echo</span> <span class="string">&#x27;vm.swappiness=10&#x27;</span> &gt;&gt; /etc/sysctl.conf</span><br><span class="line">[root@hadoop1 ~]# sysctl -p</span><br><span class="line">vm.swappiness = 10</span><br><span class="line"></span><br><span class="line">[root@hadoop2 ~]# <span class="built_in">echo</span> <span class="string">&#x27;vm.swappiness=10&#x27;</span> &gt;&gt; /etc/sysctl.conf</span><br><span class="line">[root@hadoop2 ~]# sysctl -p</span><br><span class="line">vm.swappiness = 10</span><br><span class="line"></span><br><span class="line">[root@hadoop3 ~]# <span class="built_in">echo</span> <span class="string">&#x27;vm.swappiness=10&#x27;</span> &gt;&gt; /etc/sysctl.conf</span><br><span class="line">[root@hadoop4 ~]# sysctl -p</span><br><span class="line">vm.swappiness = 10</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#解决已启用透明大页面压缩，可能会导致重大性能问题。</span></span><br><span class="line"><span class="comment">#hadoop1机器：</span></span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line">[root@hadoop1 ~]# <span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">[root@hadoop1 ~]# vim /etc/rc.local</span><br><span class="line">追加如下内容：</span><br><span class="line"><span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line"><span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line"></span><br><span class="line"><span class="comment">#hadoop2机器：</span></span><br><span class="line">[root@hadoop2 ~]# <span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line">[root@hadoop2 ~]# <span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">[root@hadoop2 ~]# vim /etc/rc.local</span><br><span class="line">追加如下内容：</span><br><span class="line"><span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line"><span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line"></span><br><span class="line"><span class="comment">#hadoop3机器：</span></span><br><span class="line">[root@hadoop3 ~]# <span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line">[root@hadoop3 ~]# <span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">[root@hadoop3 ~]# vim /etc/rc.local</span><br><span class="line">追加如下内容：</span><br><span class="line"><span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line"><span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br></pre></td></tr></table></figure>

<p><strong>点击页面上的重新运行：</strong></p>
<p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/13.png"></p>
<h3 id="3-11-自定义需要安装的服务"><a href="#3-11-自定义需要安装的服务" class="headerlink" title="3.11 自定义需要安装的服务"></a>3.11 自定义需要安装的服务</h3><blockquote>
<p>根据公司需求，选择安装相应的组件</p>
</blockquote>
<p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/14.png"></p>
<p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/15.png"></p>
<h3 id="3-12-分配角色"><a href="#3-12-分配角色" class="headerlink" title="3.12 分配角色"></a>3.12 分配角色</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/16.png"><br><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/17.png"><br><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/18.png"></p>
<h3 id="3-13-集群设置，数据库设置"><a href="#3-13-集群设置，数据库设置" class="headerlink" title="3.13 集群设置，数据库设置"></a>3.13 集群设置，数据库设置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 ~]# mysql -ucdh -h192.168.101.116 -p</span><br><span class="line">Enter password:</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection <span class="built_in">id</span> is 392</span><br><span class="line">Server version: 5.6.45 MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type <span class="string">&#x27;help;&#x27;</span> or <span class="string">&#x27;\h&#x27;</span> <span class="keyword">for</span> <span class="built_in">help</span>. Type <span class="string">&#x27;\c&#x27;</span> to clear the current input statement.</span><br><span class="line"></span><br><span class="line">mysql&gt; create database hive;        <span class="comment">#创建hive库</span></span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; create database ooize;       <span class="comment">#创建ooize库</span></span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure>

<p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/19.png"><br><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/20.png"></p>
<h3 id="3-14-等待安装完成"><a href="#3-14-等待安装完成" class="headerlink" title="3.14 等待安装完成"></a>3.14 等待安装完成</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/21.png"><br><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/22.png"></p>
<p><strong>解决办法（所有agent节点都操作）：</strong></p>
<p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/23.png"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop01 init.d]# <span class="built_in">mkdir</span> /usr/java</span><br><span class="line">[root@hadoop01 init.d]# <span class="built_in">ln</span> -s /usr/local/jdk1.8.0_181 /usr/java/default</span><br></pre></td></tr></table></figure>

<h3 id="3-15-完成安装后，点击继续"><a href="#3-15-完成安装后，点击继续" class="headerlink" title="3.15 完成安装后，点击继续"></a>3.15 完成安装后，点击继续</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/24.png"></p>
<h3 id="3-16-CDH部署成功界面"><a href="#3-16-CDH部署成功界面" class="headerlink" title="3.16 CDH部署成功界面"></a>3.16 CDH部署成功界面</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/25.png"><br><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/26.png"></p>
<h2 id="四，验证CHD服务是否可用"><a href="#四，验证CHD服务是否可用" class="headerlink" title="四，验证CHD服务是否可用"></a>四，验证CHD服务是否可用</h2><h3 id="4-1-验证zookeeper是否可以正常使用"><a href="#4-1-验证zookeeper是否可以正常使用" class="headerlink" title="4.1 验证zookeeper是否可以正常使用"></a>4.1 验证zookeeper是否可以正常使用</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 ~]# zookeeper-client -server hadoop1</span><br><span class="line">Connecting to hadoop1</span><br><span class="line">2019-09-02 17:52:27,419 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.5-cdh5.13.3--1, built on 03/17/2018 11:30 GMT</span><br><span class="line">2019-09-02 17:52:27,422 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=hadoop1</span><br><span class="line">2019-09-02 17:52:27,422 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.8.0_181</span><br><span class="line">2019-09-02 17:52:27,426 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation</span><br><span class="line">2019-09-02 17:52:27,426 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/usr/local/jdk1.8.0_181/jre</span><br><span class="line">2019-09-02 17:52:27,426 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/lib/zookeeper/bin/../build/classes:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/lib/zookeeper/bin/../build/lib/*.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/lib/zookeeper/bin/../lib/slf4j-log4j12.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/lib/zookeeper/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/lib/zookeeper/bin/../lib/slf4j-api-1.7.5.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/lib/zookeeper/bin/../lib/netty-3.10.5.Final.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/lib/zookeeper/bin/../lib/log4j-1.2.16.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/lib/zookeeper/bin/../lib/jline-2.11.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/lib/zookeeper/bin/../zookeeper-3.4.5-cdh5.13.3.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/lib/zookeeper/bin/../src/java/lib/*.jar:/etc/zookeeper/conf:.:/usr/local/jdk/lib:/usr/local/jdk/lib/tools.jar:/etc/zookeeper/conf:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/bin/../lib/zookeeper/zookeeper.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/bin/../lib/zookeeper/zookeeper-3.4.5-cdh5.13.3.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/bin/../lib/zookeeper/lib/slf4j-log4j12.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/bin/../lib/zookeeper/lib/slf4j-log4j12-1.7.5.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/bin/../lib/zookeeper/lib/slf4j-api-1.7.5.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/bin/../lib/zookeeper/lib/netty-3.10.5.Final.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/bin/../lib/zookeeper/lib/log4j-1.2.16.jar:/opt/cloudera/parcels/CDH-5.13.3-1.cdh5.13.3.p0.2/bin/../lib/zookeeper/lib/jline-2.11.jar</span><br><span class="line">2019-09-02 17:52:27,426 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib</span><br><span class="line">2019-09-02 17:52:27,426 [myid:] - INFO  [main:Environment@100] - Client environment:java.io.tmpdir=/tmp</span><br><span class="line">2019-09-02 17:52:27,426 [myid:] - INFO  [main:Environment@100] - Client environment:java.compiler=&lt;NA&gt;</span><br><span class="line">2019-09-02 17:52:27,426 [myid:] - INFO  [main:Environment@100] - Client environment:os.name=Linux</span><br><span class="line">2019-09-02 17:52:27,426 [myid:] - INFO  [main:Environment@100] - Client environment:os.arch=amd64</span><br><span class="line">2019-09-02 17:52:27,426 [myid:] - INFO  [main:Environment@100] - Client environment:os.version=3.10.0-862.el7.x86_64</span><br><span class="line">2019-09-02 17:52:27,426 [myid:] - INFO  [main:Environment@100] - Client environment:user.name=root</span><br><span class="line">2019-09-02 17:52:27,426 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=/root</span><br><span class="line">2019-09-02 17:52:27,427 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=/root</span><br><span class="line">2019-09-02 17:52:27,428 [myid:] - INFO  [main:ZooKeeper@438] - Initiating client connection, connectString=hadoop1 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain<span class="variable">$MyWatcher</span>@7aec35a</span><br><span class="line">Welcome to ZooKeeper!</span><br><span class="line">2019-09-02 17:52:27,455 [myid:] - INFO  [main-SendThread(hadoop1:2181):ClientCnxn<span class="variable">$SendThread</span>@975] - Opening socket connection to server hadoop1/192.168.101.116:2181. Will not attempt to authenticate using SASL (unknown error)</span><br><span class="line">JLine support is enabled</span><br><span class="line">2019-09-02 17:52:27,542 [myid:] - INFO  [main-SendThread(hadoop1:2181):ClientCnxn<span class="variable">$SendThread</span>@852] - Socket connection established, initiating session, client: /192.168.101.116:38806, server: hadoop1/192.168.101.116:2181</span><br><span class="line">2019-09-02 17:52:27,553 [myid:] - INFO  [main-SendThread(hadoop1:2181):ClientCnxn<span class="variable">$SendThread</span>@1235] - Session establishment complete on server hadoop1/192.168.101.116:2181, sessionid = 0x26cf151f2e30027, negotiated <span class="built_in">timeout</span> = 30000</span><br><span class="line"></span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected <span class="built_in">type</span>:None path:null</span><br><span class="line">[zk: hadoop1(CONNECTED) 0] <span class="built_in">ls</span> /</span><br><span class="line">[zookeeper, hbase]</span><br><span class="line">[zk: hadoop1(CONNECTED) 1] quit</span><br><span class="line">Quitting...</span><br><span class="line">2019-09-02 17:52:47,902 [myid:] - INFO  [main:ZooKeeper@684] - Session: 0x26cf151f2e30027 closed</span><br><span class="line">2019-09-02 17:52:47,902 [myid:] - INFO  [main-EventThread:ClientCnxn<span class="variable">$EventThread</span>@512] - EventThread shut down</span><br></pre></td></tr></table></figure>

<h3 id="4-2-查看hdfs目录信息（注意权限，如果你想要往指定目录写数据的话，可以指定ACL）"><a href="#4-2-查看hdfs目录信息（注意权限，如果你想要往指定目录写数据的话，可以指定ACL）" class="headerlink" title="4.2 查看hdfs目录信息（注意权限，如果你想要往指定目录写数据的话，可以指定ACL）"></a>4.2 查看hdfs目录信息（注意权限，如果你想要往指定目录写数据的话，可以指定ACL）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">root@hadoop1 ~]# hdfs dfs -<span class="built_in">ls</span> -R /</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:34 /hbase</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:34 /hbase/.tmp</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:34 /hbase/.tmp/data</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:34 /hbase/.tmp/data/hbase</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:34 /hbase/MasterProcWALs</span><br><span class="line">-rw-r--r--   2 hbase hbase               0 2019-09-02 17:34 /hbase/MasterProcWALs/state-00000000000000000002.<span class="built_in">log</span></span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:34 /hbase/WALs</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:41 /hbase/WALs/hadoop2,60020,1567416840373</span><br><span class="line">-rw-r--r--   2 hbase hbase              83 2019-09-02 17:41 /hbase/WALs/hadoop2,60020,1567416840373/hadoop2%2C60020%2C1567416840373.null0.1567417311915</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:41 /hbase/WALs/hadoop3,60020,1567416844608</span><br><span class="line">-rw-r--r--   2 hbase hbase              83 2019-09-02 17:41 /hbase/WALs/hadoop3,60020,1567416844608/hadoop3%2C60020%2C1567416844608.meta.1567417309855.meta</span><br><span class="line">-rw-r--r--   2 hbase hbase              83 2019-09-02 17:34 /hbase/WALs/hadoop3,60020,1567416844608/hadoop3%2C60020%2C1567416844608.null0.1567416849733</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:34 /hbase/data</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:34 /hbase/data/default</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:34 /hbase/data/hbase</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:34 /hbase/data/hbase/meta</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:34 /hbase/data/hbase/meta/.tabledesc</span><br><span class="line">-rw-r--r--   2 hbase hbase             398 2019-09-02 17:34 /hbase/data/hbase/meta/.tabledesc/.tableinfo.0000000001</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:34 /hbase/data/hbase/meta/.tmp</span><br><span class="line">drwxr-xr-x   - hbase hbase               0 2019-09-02 17:41 /hbase/data/hbase/meta/1588230740</span><br><span class="line"></span><br><span class="line">。。。省略若干。。。</span><br></pre></td></tr></table></figure>

<h3 id="4-3-查看hdfs的webUI界面"><a href="#4-3-查看hdfs的webUI界面" class="headerlink" title="4.3 查看hdfs的webUI界面"></a>4.3 查看hdfs的webUI界面</h3><p><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/27.png"><br><img src="/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/28.png"></p>
<p><strong>附录</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">3、HDFS-副本不足的块，报错信息：</span><br><span class="line"></span><br><span class="line">测试 HDFS 是否具有过多副本不足块。</span><br><span class="line"></span><br><span class="line">不良 : 群集中有 8 个 副本不足的块 块。群集中共有 11 个块。百分比 副本不足的块: 72.73%。 临界阈值：40.00%。</span><br><span class="line"></span><br><span class="line">操作</span><br><span class="line"></span><br><span class="line">为此服务更改“副本不足的块监控阈值”。</span><br><span class="line"></span><br><span class="line">建议</span><br><span class="line"></span><br><span class="line">这是 HDFS 服务级运行状况测试，用于检查副本不足的块数是否未超过群集块总数的某一百分比。</span><br><span class="line"></span><br><span class="line">该运行状况测试失败可能表示 DataNode 丢失。使用 HDFS fsck 命令可确定哪些文件含有副本不足的块。</span><br><span class="line"></span><br><span class="line">可使用 副本不足的块监控阈值 HDFS 服务范围内的监控设置配置该测试。</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">原因：设置的副本备份数与DataNode的个数不同。</span><br><span class="line"></span><br><span class="line">dfs.replication的默认是3，也就是说副本数--块的备份数默认为3份。</span><br><span class="line"></span><br><span class="line">但是我这只有两个DataNode。所以导致了达不到目标，副本备份不足。</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">解决方案：</span><br><span class="line"></span><br><span class="line">设置目标备份数为2</span><br><span class="line"></span><br><span class="line">通过命令修改当前备份数</span><br><span class="line"></span><br><span class="line">点击集群-HDFS-配置，搜索dfs.replication,设置为2后保存更改。</span><br><span class="line"></span><br><span class="line">dfs.replication这个参数其实只在文件被写入dfs时起作用，虽然更改了配置文件，但是不会改变之前写入的文件的备份数。</span><br><span class="line"></span><br><span class="line">所以我们还需要步骤2，在cm0中通过命令更改备份数：</span><br><span class="line"></span><br><span class="line">这里的-R 2的数字2就对应我们的DataNode个数。</span><br><span class="line"></span><br><span class="line">su  hdfs</span><br><span class="line"></span><br><span class="line">hadoop fs -setrep -R 2 /</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://kkabuzs.github.io">Kkabuzs</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://kkabuzs.github.io/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/">https://kkabuzs.github.io/articles/2019/08/30/hadoopjiqunzhi-cdh5-13-1lixiandajian/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://kkabuzs.github.io" target="_blank">kkabuzs博客屋</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a></div><div class="post-share"><div class="social-share" data-image="/themes-img/touxiang.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/articles/2019/08/26/hadoopjiqunzhispark/" title="Hadoop集群之Spark"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Hadoop集群之Spark</div></div><div class="info-2"><div class="info-item-1"> 无论你跑多少距离，放弃很容易，停下来，肉体得到暂时的舒服，但你最终会一无所得。坚持或许很难，但你最后一定会有所收获，跑过的路，永远不会欺骗自己。  Hadoop集群之Spark一，Spark概述1.1 Spark 基于内存的分布式的计算框架，是一个针对海量数据处理的非常快的通用的计算引擎(计算框架)。  1.2 特点 先进架构： 采用Scala语言编写，底层采用actormodel的akka作为通讯框架，代码十分简洁高效。基于DAG图执行引擎，减少多次计算中间结果写到HDFS的开销。建立在统一抽象的RDD之上，以基本一致的方式应对不同的大数据处理。  高效： 基于cache机制来支持需要反复迭代的计算或者多次数据共享，减少数据读取的IO开销。基于内存运算比MR要快100倍，基于硬盘的运算也比MR快10倍。  易用： 提供广泛的数据集操作类型（20+种），而MR只有两种。Spark支持Java，Python和ScalaAPI，支持交互的Python和Scala的shell  整体解决方案： Spark内存中批处理 SparkSQL交互式查询 SparkStreaming流式计算...</div></div></div></a><a class="pagination-related" href="/articles/2019/09/17/centosxunijiqiangzhiduandiankaijibaocuo/" title="CentOS虚拟机断电或强制关机，再开机出现问题：Entering emergency mode. Exit the shell to continue."><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">CentOS虚拟机断电或强制关机，再开机出现问题：Entering emergency mode. Exit the shell to continue.</div></div><div class="info-2"><div class="info-item-1"> 无论你跑多少距离，放弃很容易，停下来，肉体得到暂时的舒服，但你最终会一无所得。坚持或许很难，但你最后一定会有所收获，跑过的路，永远不会欺骗自己。  CentOS虚拟机断电或强制关机，再开机出现问题：Entering emergency mode. Exit the shell to continue. 找出问题出现在哪：  这里的 journalctl 是查看系统的日志信息；直接输入此命令查看，日志内容可能很多，快速翻页或者直接定位到最新的日志信息，发现有标红的，说明此处出现错误。  错误原因： 123failed to mount /sysroot. Dependency failed for Initrd root File System. Dependency failed for Reload configuration from the Real Root.  解决问题： 1输入命令：xfs_repair -v -L /dev/dm-0   -L 选项指定强制日志清零，强制xfs_repair将日志归零，即使它包含脏数据（元数据更改）。  </div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/articles/2019/07/02/Centos-7-Hadoop-danjiediankuaisugoujian/" title="Centos 7 Hadoop单节点快速构建"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-07-02</div><div class="info-item-2">Centos 7 Hadoop单节点快速构建</div></div><div class="info-2"><div class="info-item-1">一，快速构建Hadoop单节点 无论你跑多少距离，放弃很容易，停下来，肉体得到暂时的舒服，但你最终会一无所得。坚持或许很难，但你最后一定会有所收获，跑过的路，永远不会欺骗自己。  环境介绍    主机名 ip 描述    hadoop1 192.168.101.83 hadoop部署   1.1 下载所需安装包  jdk下载地址：https://github.com/frekele/oracle-java/releaseshadoop下载地址：http://mirror.bit.edu.cn/apache/hadoop/common/ 123#安装包已经下载完毕[root@hadoop1 ~]# lshadoop-2.9.2.tar.gz  jdk-8u181-linux-x64.tar.gz  1.2 安装java jdk12345678910111213141516[root@hadoop1 ~]# tar xf jdk-8u181-linux-x64.tar.gz -C /usr/local/[root@hadoop1 ~]# ln -s...</div></div></div></a><a class="pagination-related" href="/articles/2019/07/08/centos7bushuhadoopjiqun/" title="CentOS 7部署Hadoop集群（完全分布式）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-07-08</div><div class="info-item-2">CentOS 7部署Hadoop集群（完全分布式）</div></div><div class="info-2"><div class="info-item-1"> 无论你跑多少距离，放弃很容易，停下来，肉体得到暂时的舒服，但你最终会一无所得。坚持或许很难，但你最后一定会有所收获，跑过的路，永远不会欺骗自己。  CentOS 7部署Hadoop集群（完全分布式）测试环境  Linux版本： CentOS 7 64位Hadoop版本： hadoop-2.9.2Java版本： jdk-8u181-linux-x64   一，集群服务器节点与进程 Hadoop中的HDFS和YARN都是主从结构，主从结构中的主节点和从节点有多重概念方式：     主节点 从节点    master slave   管理者 工作者   leader followe    Hadoop集群中各个角色的名称：     服务 主节点 从节点    HDFS NameNode DataNode   YARN ResourceManager NodeManager   1.1...</div></div></div></a><a class="pagination-related" href="/articles/2019/07/11/hadoopjiqunzhihbase/" title="Hadoop集群之Hbase"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-07-11</div><div class="info-item-2">Hadoop集群之Hbase</div></div><div class="info-2"><div class="info-item-1"> 无论你跑多少距离，放弃很容易，停下来，肉体得到暂时的舒服，但你最终会一无所得。坚持或许很难，但你最后一定会有所收获，跑过的路，永远不会欺骗自己。  Hadoop集群之Hbase一，概述  HBase是一个构建在HDFS上的分布式列存储系统； HBase是基于Google BigTable模型开发的，典型的key&#x2F;value系统； HBase是Apache Hadoop生态系统中的重要一员，主要用于海量结构化数据存储； 从逻辑上讲，HBase将数据按照表、行和列进行存储。 与hadoop一样，Hbase目标主要依靠横向扩展，通过不断增加廉价的商用服务器，来增加计算和存储能力。   1.1...</div></div></div></a><a class="pagination-related" href="/articles/2019/07/09/hadoopjiqunzhihive/" title="Hadoop集群之Hive"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-07-09</div><div class="info-item-2">Hadoop集群之Hive</div></div><div class="info-2"><div class="info-item-1"> 无论你跑多少距离，放弃很容易，停下来，肉体得到暂时的舒服，但你最终会一无所得。坚持或许很难，但你最后一定会有所收获，跑过的路，永远不会欺骗自己。  Hadoop集群之Hive一，Hive概述1.1 数据仓库的概念 数据仓库（Data Warehouse）是一个面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策。  传统数据仓库面临的挑战：  无法满足快速增长的海量数据存储需求。 无法有效处理不同类型的数据。 计算和处理能力不足。  1.2 Hive简介  Hive是一个构建于Hadoop顶层的数据仓库工具，可以查询和管理PB级别的分布式数据。 支持大规模数据存储、分析，具有良好的可扩展性 某种程度上可以看作是用户编程接口，本身不存储和处理数据。 依赖分布式文件系统HDFS存储数据。 依赖分布式并行计算模型MapReduce处理数据。 定义了简单的类似SQL...</div></div></div></a><a class="pagination-related" href="/articles/2019/07/18/hadoopjiqunzhizookeeper/" title="Hadoop集群之Zookeeper"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-07-18</div><div class="info-item-2">Hadoop集群之Zookeeper</div></div><div class="info-2"><div class="info-item-1"> 无论你跑多少距离，放弃很容易，停下来，肉体得到暂时的舒服，但你最终会一无所得。坚持或许很难，但你最后一定会有所收获，跑过的路，永远不会欺骗自己。  Hadoop集群之Zookeeper一，Zookeeper概述  ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。   二，基本概念2.1...</div></div></div></a><a class="pagination-related" href="/articles/2019/08/26/hadoopjiqunzhispark/" title="Hadoop集群之Spark"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-08-26</div><div class="info-item-2">Hadoop集群之Spark</div></div><div class="info-2"><div class="info-item-1"> 无论你跑多少距离，放弃很容易，停下来，肉体得到暂时的舒服，但你最终会一无所得。坚持或许很难，但你最后一定会有所收获，跑过的路，永远不会欺骗自己。  Hadoop集群之Spark一，Spark概述1.1 Spark 基于内存的分布式的计算框架，是一个针对海量数据处理的非常快的通用的计算引擎(计算框架)。  1.2 特点 先进架构： 采用Scala语言编写，底层采用actormodel的akka作为通讯框架，代码十分简洁高效。基于DAG图执行引擎，减少多次计算中间结果写到HDFS的开销。建立在统一抽象的RDD之上，以基本一致的方式应对不同的大数据处理。  高效： 基于cache机制来支持需要反复迭代的计算或者多次数据共享，减少数据读取的IO开销。基于内存运算比MR要快100倍，基于硬盘的运算也比MR快10倍。  易用： 提供广泛的数据集操作类型（20+种），而MR只有两种。Spark支持Java，Python和ScalaAPI，支持交互的Python和Scala的shell  整体解决方案： Spark内存中批处理 SparkSQL交互式查询 SparkStreaming流式计算...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/themes-img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Kkabuzs</div><div class="author-info-description">学习记录和整理</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">77</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">三人行，必有我师！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop%E9%9B%86%E7%BE%A4%E4%B9%8B-CDH-v5-13-1-%E6%90%AD%E5%BB%BA-%E7%A6%BB%E7%BA%BF%E6%9C%AC%E5%9C%B0Parcels%EF%BC%89"><span class="toc-number">1.</span> <span class="toc-text">Hadoop集群之 CDH v5.13.1 搭建 (离线本地Parcels）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%EF%BC%8CCDH-Parcels-%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85"><span class="toc-number">1.1.</span> <span class="toc-text">一，CDH Parcels 离线安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E6%9C%AC%E5%9C%B0%E6%BA%90%E4%B8%8EPackage%E6%9C%AC%E5%9C%B0%E6%BA%90%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 本地源与Package本地源的区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%EF%BC%8C%E4%BD%BF%E7%94%A8-Parcels-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2-CDH"><span class="toc-number">1.2.</span> <span class="toc-text">二，使用 Parcels 离线部署 CDH</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E7%8E%AF%E5%A2%83%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 环境介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E9%83%A8%E7%BD%B2Cloudera-Manager"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 部署Cloudera Manager</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-%E5%9C%A8%E6%89%80%E6%9C%89%E7%9A%84%E8%8A%82%E7%82%B9%E4%B8%8A%E5%88%9B%E5%BB%BAclodera-scm%E7%94%A8%E6%88%B7"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">2.2.1 在所有的节点上创建clodera-scm用户</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-%E4%BF%AE%E6%94%B9Cloudera-Manager-Agent%E7%AB%AF%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-%E6%89%80%E6%9C%89%E6%9C%BA%E5%99%A8"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">2.2.2 修改Cloudera Manager Agent端的配置文件(所有机器)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-3-%E5%88%9D%E5%A7%8B%E5%8C%96CM-Server%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">2.2.3 初始化CM Server数据库</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E5%88%B6%E4%BD%9CCDH%E6%9C%AC%E5%9C%B0%E6%BA%90"><span class="toc-number">1.2.3.</span> <span class="toc-text">2.3 制作CDH本地源</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-1-server%E5%88%9B%E5%BB%BAparcel-repo%E7%9B%AE%E5%BD%95"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">2.3.1 server创建parcel-repo目录</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-2-agent%E7%AB%AF%E5%88%9B%E5%BB%BAparcels%E7%9B%AE%E5%BD%95-49%E5%92%8C229%E6%9C%BA%E5%99%A8"><span class="toc-number">1.2.3.2.</span> <span class="toc-text">2.3.2 agent端创建parcels目录(49和229机器)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-3-%E5%88%B6%E4%BD%9CCDH%E6%9C%AC%E5%9C%B0%E6%BA%90"><span class="toc-number">1.2.3.3.</span> <span class="toc-text">2.3.3 制作CDH本地源</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E5%90%AF%E5%8A%A8CM%E7%9A%84Server%EF%BC%8CAgent%E7%AB%AF"><span class="toc-number">1.2.4.</span> <span class="toc-text">2.4 启动CM的Server，Agent端</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-1-%E5%90%AF%E5%8A%A8Cloudera-Manager-Server%E7%AB%AF"><span class="toc-number">1.2.4.1.</span> <span class="toc-text">2.4.1 启动Cloudera Manager Server端</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-2-%E5%90%AF%E5%8A%A8Cloudera-Manager-Agent%E7%AB%AF"><span class="toc-number">1.2.4.2.</span> <span class="toc-text">2.4.2 启动Cloudera Manager Agent端</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-%E8%AE%BF%E9%97%AEwebUI%E7%95%8C%E9%9D%A2"><span class="toc-number">1.2.5.</span> <span class="toc-text">2.5 访问webUI界面</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%EF%BC%8C%E5%9F%BA%E4%BA%8ECM%E7%9A%84WebUI%E9%83%A8%E7%BD%B2CDH%E9%9B%86%E7%BE%A4"><span class="toc-number">1.3.</span> <span class="toc-text">三，基于CM的WebUI部署CDH集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-CM%E7%9A%84webUI%E7%95%8C%E9%9D%A2%E9%BB%98%E8%AE%A4%E7%9A%84%E7%94%A8%E6%88%B7%E5%90%8D-%E5%AF%86%E7%A0%81%E9%83%BD%E6%98%AF%E5%B0%8F%E5%86%99%E7%9A%84admin"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 CM的webUI界面默认的用户名&#x2F;密码都是小写的admin</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E5%90%8C%E6%84%8F%E5%B9%B6%E7%BB%A7%E7%BB%AD"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 同意并继续</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E9%80%89%E6%8B%A9CM%E7%9A%84%E5%85%8D%E8%B4%B9%E7%89%88%E6%9C%AC"><span class="toc-number">1.3.3.</span> <span class="toc-text">3.3 选择CM的免费版本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E7%82%B9%E5%87%BB%E7%BB%A7%E7%BB%AD"><span class="toc-number">1.3.4.</span> <span class="toc-text">3.4 点击继续</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E4%B8%BA-CDH-%E7%BE%A4%E9%9B%86%E5%AE%89%E8%A3%85%E6%8C%87%E5%AE%9A%E4%B8%BB%E6%9C%BA"><span class="toc-number">1.3.5.</span> <span class="toc-text">3.5 为 CDH 群集安装指定主机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-6-%E9%80%89%E6%8B%A9CDH%E6%9C%AC%E5%9C%B0%E7%89%88%E6%9C%AC%EF%BC%88%E5%8D%B3%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E4%B8%8B%E8%BD%BD%E5%A5%BD%E7%9A%84%E7%89%88%E6%9C%AC%EF%BC%89"><span class="toc-number">1.3.6.</span> <span class="toc-text">3.6 选择CDH本地版本（即我们自己下载好的版本）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-7-%E5%BD%93CDH%E5%AE%89%E8%A3%85%E5%AE%8C%E6%AF%95%E5%90%8E%EF%BC%8C%E7%82%B9%E5%87%BB%E7%BB%A7%E7%BB%AD"><span class="toc-number">1.3.7.</span> <span class="toc-text">3.7 当CDH安装完毕后，点击继续</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-8-%E7%AD%89%E5%BE%85%E6%A3%80%E6%9F%A5%E4%B8%BB%E6%9C%BA%E5%AE%8C%E6%88%90"><span class="toc-number">1.3.8.</span> <span class="toc-text">3.8 等待检查主机完成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-9-%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E6%A0%B9%E6%8D%AE%E4%B8%8B%E9%9D%A2%E7%9A%84%E6%8F%90%E7%A4%BA%E5%8E%BB%E7%9B%B8%E5%BA%94%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%81%9A%E5%85%B7%E4%BD%93%E7%9A%84%E6%93%8D%E4%BD%9C%EF%BC%8C%E5%81%9A%E5%AE%8C%E6%93%8D%E4%BD%9C%E5%90%8E%E7%82%B9%E5%87%BB%E2%80%9C%E9%87%8D%E6%96%B0%E8%BF%90%E8%A1%8C%E2%80%9D%E4%BB%A5%E9%AA%8C%E8%AF%81%E4%BD%A0%E6%98%AF%E5%90%A6%E9%85%8D%E7%BD%AE%E6%88%90%E5%8A%9F%EF%BC%81"><span class="toc-number">1.3.9.</span> <span class="toc-text">3.9 我们可以根据下面的提示去相应的服务器做具体的操作，做完操作后点击“重新运行”以验证你是否配置成功！</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-10-%E8%A7%A3%E5%86%B3%E5%91%8A%E8%AD%A6%E4%BF%A1%E6%81%AF%E5%90%8E%EF%BC%8C%E7%82%B9%E5%87%BB%E5%AE%8C%E6%88%90"><span class="toc-number">1.3.10.</span> <span class="toc-text">3.10 解决告警信息后，点击完成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-11-%E8%87%AA%E5%AE%9A%E4%B9%89%E9%9C%80%E8%A6%81%E5%AE%89%E8%A3%85%E7%9A%84%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.3.11.</span> <span class="toc-text">3.11 自定义需要安装的服务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-12-%E5%88%86%E9%85%8D%E8%A7%92%E8%89%B2"><span class="toc-number">1.3.12.</span> <span class="toc-text">3.12 分配角色</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-13-%E9%9B%86%E7%BE%A4%E8%AE%BE%E7%BD%AE%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E7%BD%AE"><span class="toc-number">1.3.13.</span> <span class="toc-text">3.13 集群设置，数据库设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-14-%E7%AD%89%E5%BE%85%E5%AE%89%E8%A3%85%E5%AE%8C%E6%88%90"><span class="toc-number">1.3.14.</span> <span class="toc-text">3.14 等待安装完成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-15-%E5%AE%8C%E6%88%90%E5%AE%89%E8%A3%85%E5%90%8E%EF%BC%8C%E7%82%B9%E5%87%BB%E7%BB%A7%E7%BB%AD"><span class="toc-number">1.3.15.</span> <span class="toc-text">3.15 完成安装后，点击继续</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-16-CDH%E9%83%A8%E7%BD%B2%E6%88%90%E5%8A%9F%E7%95%8C%E9%9D%A2"><span class="toc-number">1.3.16.</span> <span class="toc-text">3.16 CDH部署成功界面</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%EF%BC%8C%E9%AA%8C%E8%AF%81CHD%E6%9C%8D%E5%8A%A1%E6%98%AF%E5%90%A6%E5%8F%AF%E7%94%A8"><span class="toc-number">1.4.</span> <span class="toc-text">四，验证CHD服务是否可用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E9%AA%8C%E8%AF%81zookeeper%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E6%AD%A3%E5%B8%B8%E4%BD%BF%E7%94%A8"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1 验证zookeeper是否可以正常使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E6%9F%A5%E7%9C%8Bhdfs%E7%9B%AE%E5%BD%95%E4%BF%A1%E6%81%AF%EF%BC%88%E6%B3%A8%E6%84%8F%E6%9D%83%E9%99%90%EF%BC%8C%E5%A6%82%E6%9E%9C%E4%BD%A0%E6%83%B3%E8%A6%81%E5%BE%80%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95%E5%86%99%E6%95%B0%E6%8D%AE%E7%9A%84%E8%AF%9D%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%8C%87%E5%AE%9AACL%EF%BC%89"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2 查看hdfs目录信息（注意权限，如果你想要往指定目录写数据的话，可以指定ACL）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E6%9F%A5%E7%9C%8Bhdfs%E7%9A%84webUI%E7%95%8C%E9%9D%A2"><span class="toc-number">1.4.3.</span> <span class="toc-text">4.3 查看hdfs的webUI界面</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/articles/2025/04/22/mongodb-6-0-21-lixian-fenpianjiqun/" title="MongoDB-6.0.21离线分片集群部署">MongoDB-6.0.21离线分片集群部署</a><time datetime="2025-04-21T17:53:44.000Z" title="发表于 2025-04-22 01:53:44">2025-04-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/articles/2025/04/22/mongodb-6-0-21-lixian-fubenjibushu/" title="MongoDB-6.0.21副本集离线部署手册-（Replica Set）副本集模式">MongoDB-6.0.21副本集离线部署手册-（Replica Set）副本集模式</a><time datetime="2025-04-21T17:51:21.000Z" title="发表于 2025-04-22 01:51:21">2025-04-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/articles/2025/04/21/mongodb-6-0-21-lixian-danjiedianbushu/" title="MongoDB-6.0.21离线单节点部署">MongoDB-6.0.21离线单节点部署</a><time datetime="2025-04-21T15:55:06.000Z" title="发表于 2025-04-21 23:55:06">2025-04-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/articles/2023/05/15/piliangshanchuk8szhongyibeiquzhudepod/" title="批量删除k8s中已经被驱逐（Evicted）的pod">批量删除k8s中已经被驱逐（Evicted）的pod</a><time datetime="2023-05-15T01:19:40.000Z" title="发表于 2023-05-15 09:19:40">2023-05-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/articles/2023/05/10/jichengyupaisheng/" title="继承与派生">继承与派生</a><time datetime="2023-05-10T05:52:52.000Z" title="发表于 2023-05-10 13:52:52">2023-05-10</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Kkabuzs</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>